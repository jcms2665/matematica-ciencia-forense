library(proxy)
library(tm)
library(proxy)
calificar_respuesta <- function(respuesta_usuario, respuesta_correcta) {
# Tokenización y preprocesamiento manual de los textos
preprocesar_texto <- function(texto) {
texto <- tolower(texto)  # Convertir a minúsculas
texto <- removePunctuation(texto)  # Eliminar puntuación
texto <- removeNumbers(texto)  # Eliminar números
texto <- removeWords(texto, stopwords("en"))  # Eliminar palabras vacías
texto <- stripWhitespace(texto)  # Eliminar espacios en blanco extra
return(unlist(strsplit(texto, "\\s+")))  # Dividir en tokens (palabras)
}
# Obtener los tokens de ambos textos
tokens_usuario <- preprocesar_texto(respuesta_usuario)
tokens_correcta <- preprocesar_texto(respuesta_correcta)
# Crear un vocabulario común
vocabulario <- unique(c(tokens_usuario, tokens_correcta))
# Crear vectores TF-IDF a nivel de tokens
vector_usuario <- table(factor(tokens_usuario, levels = vocabulario))
vector_correcta <- table(factor(tokens_correcta, levels = vocabulario))
# Convertir vectores a formato numérico y asegurar dimensiones compatibles
vector_usuario <- as.numeric(vector_usuario)
vector_correcta <- as.numeric(vector_correcta)
# Crear una matriz con los vectores para la similitud coseno
matriz <- rbind(vector_usuario, vector_correcta)
# Calcular la similitud coseno
similarity <- 1 - proxy::dist(matriz, method = "cosine")[1, 2]
# Calcular la calificación base
calificacion_base <- round(similarity * 10, 1)
# Ajustar la calificación final con el límite de 10
calificacion_final <- round(min(calificacion_base, 10), 1)
return(list(calificacion_final = calificacion_final, similarity = similarity))
}
# Evaluar texto1 con base en texto2
texto1 <- "promedio de cosas"
texto2 <- "es el número dividido entre dos cantidades"
resultado <- calificar_respuesta(texto1, texto2)
library(SnowballC)
library(textTinyR)
library(tm)
library(proxy)
library(tm)
library(proxy)
calificar_respuesta <- function(respuesta_usuario, respuesta_correcta) {
# Tokenización y preprocesamiento manual de los textos
preprocesar_texto <- function(texto) {
texto <- tolower(texto)  # Convertir a minúsculas
texto <- removePunctuation(texto)  # Eliminar puntuación
texto <- removeNumbers(texto)  # Eliminar números
texto <- removeWords(texto, stopwords("en"))  # Eliminar palabras vacías
texto <- stripWhitespace(texto)  # Eliminar espacios en blanco extra
return(unlist(strsplit(texto, "\\s+")))  # Dividir en tokens (palabras)
}
# Obtener los tokens de ambos textos
tokens_usuario <- preprocesar_texto(respuesta_usuario)
tokens_correcta <- preprocesar_texto(respuesta_correcta)
# Crear un vocabulario común
vocabulario <- unique(c(tokens_usuario, tokens_correcta))
# Crear vectores TF-IDF a nivel de tokens
vector_usuario <- table(factor(tokens_usuario, levels = vocabulario))
vector_correcta <- table(factor(tokens_correcta, levels = vocabulario))
# Convertir vectores a formato numérico y asegurar dimensiones compatibles
vector_usuario <- as.numeric(vector_usuario)
vector_correcta <- as.numeric(vector_correcta)
# Crear una matriz con los vectores para la similitud coseno
matriz <- rbind(vector_usuario, vector_correcta)
# Calcular la similitud coseno
similarity <- 1 - proxy::dist(matriz, method = "cosine")[1, 2]
# Calcular la calificación base
calificacion_base <- round(similarity * 10, 1)
# Ajustar la calificación final con el límite de 10
calificacion_final <- round(min(calificacion_base, 10), 1)
return(list(calificacion_final = calificacion_final, similarity = similarity))
}
# Evaluar texto1 con base en texto2
texto1 <- "promedio de cosas"
texto2 <- "es el número dividido entre dos cantidades"
resultado <- calificar_respuesta(texto1, texto2)
library(tm)
library(proxy)
calificar_respuesta <- function(respuesta_usuario, respuesta_correcta) {
# Tokenización y preprocesamiento manual de los textos
preprocesar_texto <- function(texto) {
texto <- tolower(texto)  # Convertir a minúsculas
texto <- removePunctuation(texto)  # Eliminar puntuación
texto <- removeNumbers(texto)  # Eliminar números
texto <- removeWords(texto, stopwords("en"))  # Eliminar palabras vacías
texto <- stripWhitespace(texto)  # Eliminar espacios en blanco extra
return(unlist(strsplit(texto, "\\s+")))  # Dividir en tokens (palabras)
}
# Obtener los tokens de ambos textos
tokens_usuario <- preprocesar_texto(respuesta_usuario)
tokens_correcta <- preprocesar_texto(respuesta_correcta)
# Crear un vocabulario común
vocabulario <- unique(c(tokens_usuario, tokens_correcta))
# Crear vectores TF a nivel de tokens
vector_usuario <- table(factor(tokens_usuario, levels = vocabulario))
vector_correcta <- table(factor(tokens_correcta, levels = vocabulario))
# Convertir vectores a formato numérico y asegurar dimensiones compatibles
vector_usuario <- as.numeric(vector_usuario)
vector_correcta <- as.numeric(vector_correcta)
# Verificar que los vectores tengan elementos no nulos
if (length(vector_usuario) == 0 || length(vector_correcta) == 0) {
stop("Los textos no contienen tokens compatibles para comparación.")
}
# Crear una matriz con los vectores para la similitud coseno
matriz <- rbind(vector_usuario, vector_correcta)
# Calcular la similitud coseno
similarity <- 1 - as.numeric(proxy::dist(matriz, method = "cosine"))
# Calcular la calificación base
calificacion_base <- round(similarity * 10, 1)
# Ajustar la calificación final con el límite de 10
calificacion_final <- round(min(calificacion_base, 10), 1)
return(list(calificacion_final = calificacion_final, similarity = similarity))
}
# Evaluar texto1 con base en texto2
texto1 <- "promedio de cosas"
texto2 <- "es el número dividido entre dos cantidades"
resultado <- calificar_respuesta(texto1, texto2)
# Mostrar resultados
cat("Calificación Final:", resultado$calificacion_final, "\n")
cat("Similitud Coseno:", resultado$similarity, "\n")
library(tm)
library(proxy)
calificar_respuesta <- function(respuesta_usuario, respuesta_correcta) {
# Tokenización y preprocesamiento manual de los textos
preprocesar_texto <- function(texto) {
texto <- tolower(texto)  # Convertir a minúsculas
texto <- removePunctuation(texto)  # Eliminar puntuación
texto <- removeNumbers(texto)  # Eliminar números
texto <- removeWords(texto, stopwords("en"))  # Eliminar palabras vacías
texto <- stripWhitespace(texto)  # Eliminar espacios en blanco extra
return(unlist(strsplit(texto, "\\s+")))  # Dividir en tokens (palabras)
}
# Obtener los tokens de ambos textos
tokens_usuario <- preprocesar_texto(respuesta_usuario)
tokens_correcta <- preprocesar_texto(respuesta_correcta)
# Crear un vocabulario común
vocabulario <- unique(c(tokens_usuario, tokens_correcta))
# Crear vectores TF a nivel de tokens
vector_usuario <- table(factor(tokens_usuario, levels = vocabulario))
vector_correcta <- table(factor(tokens_correcta, levels = vocabulario))
# Convertir vectores a formato numérico y asegurar dimensiones compatibles
vector_usuario <- as.numeric(vector_usuario)
vector_correcta <- as.numeric(vector_correcta)
# Verificar que los vectores tengan elementos no nulos
if (length(vector_usuario) == 0 || length(vector_correcta) == 0) {
stop("Los textos no contienen tokens compatibles para comparación.")
}
# Crear una matriz con los vectores para la similitud coseno
matriz <- rbind(vector_usuario, vector_correcta)
# Calcular la similitud coseno
similarity <- 1 - as.numeric(proxy::dist(matriz, method = "cosine"))
# Calcular la calificación base
calificacion_base <- round(similarity * 10, 1)
# Ajustar la calificación final con el límite de 10
calificacion_final <- round(min(calificacion_base, 10), 1)
return(list(calificacion_final = calificacion_final, similarity = similarity))
}
# Evaluar texto1 con base en texto2
texto1 <- "la suma y división de cosas"
texto2 <- "Es el valor que se obtiene al dividir la suma de un conglomerado de números entre la cantidad de ellos."
resultado <- calificar_respuesta(texto1, texto2)
# Mostrar resultados
cat("Calificación Final:", resultado$calificacion_final, "\n")
cat("Similitud Coseno:", resultado$similarity, "\n")
library(tm)
library(proxy)
calificar_respuesta <- function(respuesta_usuario, respuesta_correcta) {
# Tokenización y preprocesamiento manual de los textos
preprocesar_texto <- function(texto) {
texto <- tolower(texto)  # Convertir a minúsculas
texto <- removePunctuation(texto)  # Eliminar puntuación
texto <- removeNumbers(texto)  # Eliminar números
texto <- removeWords(texto, stopwords("en"))  # Eliminar palabras vacías
texto <- stripWhitespace(texto)  # Eliminar espacios en blanco extra
return(unlist(strsplit(texto, "\\s+")))  # Dividir en tokens (palabras)
}
# Obtener los tokens de ambos textos
tokens_usuario <- preprocesar_texto(respuesta_usuario)
tokens_correcta <- preprocesar_texto(respuesta_correcta)
# Crear un vocabulario común
vocabulario <- unique(c(tokens_usuario, tokens_correcta))
# Crear vectores TF a nivel de tokens
vector_usuario <- table(factor(tokens_usuario, levels = vocabulario))
vector_correcta <- table(factor(tokens_correcta, levels = vocabulario))
# Convertir vectores a formato numérico y asegurar dimensiones compatibles
vector_usuario <- as.numeric(vector_usuario)
vector_correcta <- as.numeric(vector_correcta)
# Verificar que los vectores tengan elementos no nulos
if (length(vector_usuario) == 0 || length(vector_correcta) == 0) {
stop("Los textos no contienen tokens compatibles para comparación.")
}
# Crear una matriz con los vectores para la similitud coseno
matriz <- rbind(vector_usuario, vector_correcta)
# Calcular la similitud coseno
similarity <- 1 - as.numeric(proxy::dist(matriz, method = "cosine"))
# Calcular la calificación base
calificacion_base <- round(similarity * 10, 1)
# Ajustar la calificación final con el límite de 10
calificacion_final <- round(min(calificacion_base+4.1, 10), 1)
return(list(calificacion_final = calificacion_final, similarity = similarity))
}
# Evaluar texto1 con base en texto2
texto1 <- "la suma y división de cosas"
texto2 <- "Es el valor que se obtiene al dividir la suma de un conglomerado de números entre la cantidad de ellos."
resultado <- calificar_respuesta(texto1, texto2)
# Mostrar resultados
cat("Calificación Final:", resultado$calificacion_final, "\n")
library(tm)
library(proxy)
calificar_respuesta <- function(respuesta_usuario, respuesta_correcta) {
# Tokenización y preprocesamiento manual de los textos
preprocesar_texto <- function(texto) {
texto <- tolower(texto)  # Convertir a minúsculas
texto <- removePunctuation(texto)  # Eliminar puntuación
texto <- removeNumbers(texto)  # Eliminar números
texto <- removeWords(texto, stopwords("en"))  # Eliminar palabras vacías
texto <- stripWhitespace(texto)  # Eliminar espacios en blanco extra
return(unlist(strsplit(texto, "\\s+")))  # Dividir en tokens (palabras)
}
# Obtener los tokens de ambos textos
tokens_usuario <- preprocesar_texto(respuesta_usuario)
tokens_correcta <- preprocesar_texto(respuesta_correcta)
# Crear un vocabulario común
vocabulario <- unique(c(tokens_usuario, tokens_correcta))
# Crear vectores TF a nivel de tokens
vector_usuario <- table(factor(tokens_usuario, levels = vocabulario))
vector_correcta <- table(factor(tokens_correcta, levels = vocabulario))
# Convertir vectores a formato numérico y asegurar dimensiones compatibles
vector_usuario <- as.numeric(vector_usuario)
vector_correcta <- as.numeric(vector_correcta)
# Verificar que los vectores tengan elementos no nulos
if (length(vector_usuario) == 0 || length(vector_correcta) == 0) {
stop("Los textos no contienen tokens compatibles para comparación.")
}
# Crear una matriz con los vectores para la similitud coseno
matriz <- rbind(vector_usuario, vector_correcta)
# Calcular la similitud coseno
similarity <- 1 - as.numeric(proxy::dist(matriz, method = "cosine"))
# Calcular la calificación base
calificacion_base <- round(similarity * 10, 1)
# Ajustar la calificación final con el límite de 10
calificacion_final <- round(min(calificacion_base, 10), 1)
# Identificar palabras faltantes
palabras_faltantes <- setdiff(tokens_correcta, tokens_usuario)
# Generar texto sobre palabras faltantes
texto_faltantes <- if (length(palabras_faltantes) > 0) {
paste("Palabras faltantes en la respuesta del usuario:",
paste(palabras_faltantes, collapse = ", "))
} else {
"La respuesta del usuario incluye todas las palabras clave de la respuesta correcta."
}
# Retornar resultados
return(list(
calificacion_final = calificacion_final,
similarity = similarity,
texto_faltantes = texto_faltantes
))
}
# Evaluar texto1 con base en texto2
texto1 <- "promedio de cosas"
texto2 <- "es el número dividido entre dos cantidades"
resultado <- calificar_respuesta(texto1, texto2)
# Mostrar resultados
cat("Calificación Final:", resultado$calificacion_final, "\n")
cat("Similitud Coseno:", resultado$similarity, "\n")
cat("Análisis de Palabras Faltantes:", resultado$texto_faltantes, "\n")
library(tm)
library(proxy)
calificar_respuesta <- function(respuesta_usuario, respuesta_correcta) {
# Tokenización y preprocesamiento manual de los textos
preprocesar_texto <- function(texto) {
texto <- tolower(texto)  # Convertir a minúsculas
texto <- removePunctuation(texto)  # Eliminar puntuación
texto <- removeNumbers(texto)  # Eliminar números
texto <- removeWords(texto, stopwords("en"))  # Eliminar palabras vacías
texto <- stripWhitespace(texto)  # Eliminar espacios en blanco extra
return(unlist(strsplit(texto, "\\s+")))  # Dividir en tokens (palabras)
}
# Obtener los tokens de ambos textos
tokens_usuario <- preprocesar_texto(respuesta_usuario)
tokens_correcta <- preprocesar_texto(respuesta_correcta)
# Crear un vocabulario común
vocabulario <- unique(c(tokens_usuario, tokens_correcta))
# Crear vectores TF a nivel de tokens
vector_usuario <- table(factor(tokens_usuario, levels = vocabulario))
vector_correcta <- table(factor(tokens_correcta, levels = vocabulario))
# Convertir vectores a formato numérico y asegurar dimensiones compatibles
vector_usuario <- as.numeric(vector_usuario)
vector_correcta <- as.numeric(vector_correcta)
# Verificar que los vectores tengan elementos no nulos
if (length(vector_usuario) == 0 || length(vector_correcta) == 0) {
stop("Los textos no contienen tokens compatibles para comparación.")
}
# Crear una matriz con los vectores para la similitud coseno
matriz <- rbind(vector_usuario, vector_correcta)
# Calcular la similitud coseno
similarity <- 1 - as.numeric(proxy::dist(matriz, method = "cosine"))
# Calcular la calificación base
calificacion_base <- round(similarity * 10, 1)
# Ajustar la calificación final con el límite de 10
calificacion_final <- round(min(calificacion_base+4.1, 10), 1)
return(list(calificacion_final = calificacion_final, similarity = similarity))
}
# Evaluar texto1 con base en texto2
texto1 <- "la suma y división de cosas"
texto2 <- "Es el valor que se obtiene al dividir la suma de un conglomerado de números entre la cantidad de ellos."
resultado <- calificar_respuesta(texto1, texto2)
# Mostrar resultados
cat("Calificación Final:", resultado$calificacion_final, "\n")
library(tm)
library(proxy)
calificar_respuesta <- function(respuesta_usuario, respuesta_correcta) {
# Tokenización y preprocesamiento manual de los textos
preprocesar_texto <- function(texto) {
texto <- tolower(texto)  # Convertir a minúsculas
texto <- removePunctuation(texto)  # Eliminar puntuación
texto <- removeNumbers(texto)  # Eliminar números
texto <- removeWords(texto, stopwords("en"))  # Eliminar palabras vacías
texto <- stripWhitespace(texto)  # Eliminar espacios en blanco extra
return(unlist(strsplit(texto, "\\s+")))  # Dividir en tokens (palabras)
}
# Obtener los tokens de ambos textos
tokens_usuario <- preprocesar_texto(respuesta_usuario)
tokens_correcta <- preprocesar_texto(respuesta_correcta)
# Crear un vocabulario común
vocabulario <- unique(c(tokens_usuario, tokens_correcta))
# Crear vectores TF a nivel de tokens
vector_usuario <- table(factor(tokens_usuario, levels = vocabulario))
vector_correcta <- table(factor(tokens_correcta, levels = vocabulario))
# Convertir vectores a formato numérico y asegurar dimensiones compatibles
vector_usuario <- as.numeric(vector_usuario)
vector_correcta <- as.numeric(vector_correcta)
# Verificar que los vectores tengan elementos no nulos
if (length(vector_usuario) == 0 || length(vector_correcta) == 0) {
stop("Los textos no contienen tokens compatibles para comparación.")
}
# Crear una matriz con los vectores para la similitud coseno
matriz <- rbind(vector_usuario, vector_correcta)
# Calcular la similitud coseno
similarity <- 1 - as.numeric(proxy::dist(matriz, method = "cosine"))
# Calcular la calificación base
calificacion_base <- round(similarity * 10, 1)
# Ajustar la calificación final con el límite de 10
calificacion_final <- round(min(calificacion_base+4.1, 10), 1)
return(list(calificacion_final = calificacion_final, similarity = similarity))
}
# Evaluar texto1 con base en texto2
texto1 <- "la suma de un grupo y división de cosas"
texto2 <- "Es el valor que se obtiene al dividir la suma de un conglomerado de números entre la cantidad de ellos."
resultado <- calificar_respuesta(texto1, texto2)
# Mostrar resultados
cat("Calificación Final:", resultado$calificacion_final, "\n")
library(tm)
library(proxy)
calificar_respuesta <- function(respuesta_usuario, respuesta_correcta) {
preprocesar_texto <- function(texto) {
texto <- tolower(texto)  # Convertir a minúsculas
texto <- removePunctuation(texto)  # Eliminar puntuación
texto <- removeNumbers(texto)  # Eliminar números
texto <- removeWords(texto, stopwords("en"))  # Eliminar palabras vacías
texto <- stripWhitespace(texto)  # Eliminar espacios en blanco extra
return(unlist(strsplit(texto, "\\s+")))  # Dividir en tokens (palabras)
}
tokens_usuario <- preprocesar_texto(respuesta_usuario)
tokens_correcta <- preprocesar_texto(respuesta_correcta)
vocabulario <- unique(c(tokens_usuario, tokens_correcta))
vector_usuario <- table(factor(tokens_usuario, levels = vocabulario))
vector_correcta <- table(factor(tokens_correcta, levels = vocabulario))
vector_usuario <- as.numeric(vector_usuario)
vector_correcta <- as.numeric(vector_correcta)
if (length(vector_usuario) == 0 || length(vector_correcta) == 0) {
stop("Los textos no contienen tokens compatibles para comparación.")
}
matriz <- rbind(vector_usuario, vector_correcta)
similarity <- 1 - as.numeric(proxy::dist(matriz, method = "cosine"))
calificacion_base <- round(similarity * 10, 1)
calificacion_final <- round(min(calificacion_base+4.1, 10), 1)
return(list(calificacion_final = calificacion_final, similarity = similarity))
}
texto1 <- "dispersión de los datos"
texto2 <- "Indica qué tan dispersos están los datos respecto a la media"
resultado <- calificar_respuesta(texto1, texto2)
cat("Calificación Final:", resultado$calificacion_final, "\n")
library(tm)
library(proxy)
calificar_respuesta <- function(respuesta_usuario, respuesta_correcta) {
preprocesar_texto <- function(texto) {
texto <- tolower(texto)  # Convertir a minúsculas
texto <- removePunctuation(texto)  # Eliminar puntuación
texto <- removeNumbers(texto)  # Eliminar números
texto <- removeWords(texto, stopwords("en"))  # Eliminar palabras vacías
texto <- stripWhitespace(texto)  # Eliminar espacios en blanco extra
return(unlist(strsplit(texto, "\\s+")))  # Dividir en tokens (palabras)
}
tokens_usuario <- preprocesar_texto(respuesta_usuario)
tokens_correcta <- preprocesar_texto(respuesta_correcta)
vocabulario <- unique(c(tokens_usuario, tokens_correcta))
vector_usuario <- table(factor(tokens_usuario, levels = vocabulario))
vector_correcta <- table(factor(tokens_correcta, levels = vocabulario))
vector_usuario <- as.numeric(vector_usuario)
vector_correcta <- as.numeric(vector_correcta)
if (length(vector_usuario) == 0 || length(vector_correcta) == 0) {
stop("Los textos no contienen tokens compatibles para comparación.")
}
matriz <- rbind(vector_usuario, vector_correcta)
similarity <- 1 - as.numeric(proxy::dist(matriz, method = "cosine"))
calificacion_base <- round(similarity * 10, 1)
calificacion_final <- round(min(calificacion_base+4.1, 10), 1)
return(list(calificacion_final = calificacion_final, similarity = similarity))
}
texto1 <- "dispersión de los datos media"
texto2 <- "Indica qué tan dispersos están los datos respecto a la media"
resultado <- calificar_respuesta(texto1, texto2)
cat("Calificación Final:", resultado$calificacion_final, "\n")
library(tm)
library(proxy)
calificar_respuesta <- function(respuesta_usuario, respuesta_correcta) {
preprocesar_texto <- function(texto) {
texto <- tolower(texto)  # Convertir a minúsculas
texto <- removePunctuation(texto)  # Eliminar puntuación
texto <- removeNumbers(texto)  # Eliminar números
texto <- removeWords(texto, stopwords("en"))  # Eliminar palabras vacías
texto <- stripWhitespace(texto)  # Eliminar espacios en blanco extra
return(unlist(strsplit(texto, "\\s+")))  # Dividir en tokens (palabras)
}
tokens_usuario <- preprocesar_texto(respuesta_usuario)
tokens_correcta <- preprocesar_texto(respuesta_correcta)
vocabulario <- unique(c(tokens_usuario, tokens_correcta))
vector_usuario <- table(factor(tokens_usuario, levels = vocabulario))
vector_correcta <- table(factor(tokens_correcta, levels = vocabulario))
vector_usuario <- as.numeric(vector_usuario)
vector_correcta <- as.numeric(vector_correcta)
if (length(vector_usuario) == 0 || length(vector_correcta) == 0) {
stop("Los textos no contienen tokens compatibles para comparación.")
}
matriz <- rbind(vector_usuario, vector_correcta)
similarity <- 1 - as.numeric(proxy::dist(matriz, method = "cosine"))
calificacion_base <- round(similarity * 10, 1)
calificacion_final <- round(min(calificacion_base+4.3, 10), 1)
return(list(calificacion_final = calificacion_final, similarity = similarity))
}
texto1 <- "dispersión de los datos media"
texto2 <- "Indica qué tan dispersos están los datos respecto a la media"
resultado <- calificar_respuesta(texto1, texto2)
cat("Calificación Final:", resultado$calificacion_final, "\n")
library(tm)
library(proxy)
calificar_respuesta <- function(respuesta_usuario, respuesta_correcta) {
preprocesar_texto <- function(texto) {
texto <- tolower(texto)  # Convertir a minúsculas
texto <- removePunctuation(texto)  # Eliminar puntuación
texto <- removeNumbers(texto)  # Eliminar números
texto <- removeWords(texto, stopwords("en"))  # Eliminar palabras vacías
texto <- stripWhitespace(texto)  # Eliminar espacios en blanco extra
return(unlist(strsplit(texto, "\\s+")))  # Dividir en tokens (palabras)
}
tokens_usuario <- preprocesar_texto(respuesta_usuario)
tokens_correcta <- preprocesar_texto(respuesta_correcta)
vocabulario <- unique(c(tokens_usuario, tokens_correcta))
vector_usuario <- table(factor(tokens_usuario, levels = vocabulario))
vector_correcta <- table(factor(tokens_correcta, levels = vocabulario))
vector_usuario <- as.numeric(vector_usuario)
vector_correcta <- as.numeric(vector_correcta)
if (length(vector_usuario) == 0 || length(vector_correcta) == 0) {
stop("Los textos no contienen tokens compatibles para comparación.")
}
matriz <- rbind(vector_usuario, vector_correcta)
similarity <- 1 - as.numeric(proxy::dist(matriz, method = "cosine"))
calificacion_base <- round(similarity * 10, 1)
calificacion_final <- round(min(calificacion_base+4.4, 10), 1)
return(list(calificacion_final = calificacion_final, similarity = similarity))
}
texto1 <- "dispersión de los datos media"
texto2 <- "Indica qué tan dispersos están los datos respecto a la media"
resultado <- calificar_respuesta(texto1, texto2)
cat("Calificación Final:", resultado$calificacion_final, "\n")
install.packages("rmarkdown")
setwd("G:/Mi unidad/1 Proyectos/2025/05 Estadística I/1 Material/0 Notas generales/Proyecto")
unlink("_book", recursive = TRUE)
unlink("_bookdown_files", recursive = TRUE)
unlink("_main.Rmd", recursive = TRUE)
library(bookdown)
library(rmarkdown)
library(quarto)
install.packages("quarto")
library(quarto)
unlink("_book", recursive = TRUE)
unlink("_bookdown_files", recursive = TRUE)
unlink("_main.Rmd", recursive = TRUE)
bookdown::render_book("index.Rmd", "bookdown::gitbook")
shiny::runApp()
source('G:/Mi unidad/1 Proyectos/2025/05 Estadística I/1 Material/0 Notas generales/ejecutar.R')
source('G:/Mi unidad/1 Proyectos/2025/05 Estadística I/1 Material/0 Notas generales/ejecutar.R')
source('G:/Mi unidad/1 Proyectos/2025/05 Estadística I/1 Material/0 Notas generales/ejecutar.R')
source('G:/Mi unidad/1 Proyectos/2025/05 Estadística I/1 Material/0 Notas generales/ejecutar.R')
source('G:/Mi unidad/1 Proyectos/2025/05 Estadística I/1 Material/0 Notas generales/ejecutar.R')
unlink(c("_book", "_bookdown_files", "_main.Rmd"), recursive = TRUE)
bookdown::render_book("index.Rmd", "bookdown::gitbook")
runApp()
source('G:/Mi unidad/1 Proyectos/2025/05 Estadística I/1 Material/0 Notas generales/ejecutar.R')
source('G:/Mi unidad/1 Proyectos/2025/05 Estadística I/1 Material/0 Notas generales/ejecutar.R')
runApp()
source('G:/Mi unidad/1 Proyectos/2025/05 Estadística I/1 Material/0 Notas generales/ejecutar.R')
unlink(c("_book", "_bookdown_files", "_main.Rmd"), recursive = TRUE)
bookdown::render_book("index.Rmd", "bookdown::gitbook")
shiny::runApp()
source('G:/Mi unidad/1 Proyectos/2025/05 Estadística I/1 Material/0 Notas generales/ejecutar.R')
source('G:/Mi unidad/1 Proyectos/2025/05 Estadística I/1 Material/0 Notas generales/ejecutar.R')
source('G:/Mi unidad/1 Proyectos/2025/05 Estadística I/1 Material/0 Notas generales/ejecutar.R')
